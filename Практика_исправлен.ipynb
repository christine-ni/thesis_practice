{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKmZzHEf-ZJj"
   },
   "source": [
    "Классификация, которую я использовала для размеки:\n",
    "1. Гендерно-маркированная номинация лица\n",
    "2. Гендерно-нейтральная номинация лица\n",
    "3. Дружеское или фамильярное обращение\n",
    "4. родственник\n",
    "5. Лицо, состоящее в дружеских отношениях с говорящим\n",
    "6. Лицо, состоящее в романтических отношениях с говорящим\n",
    "7. Молодой человек\n",
    "8. Взрослый человек\n",
    "9. Пожилой человек\n",
    "10. Лицо младше или одного возраста с говорящим\n",
    "0. Воплощение свойств и качеств, присущих данному полу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kP8F89i9u3kC"
   },
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrSVFX-1LtvY",
    "outputId": "47481e77-5447-440e-b8c3-9a2c2d7daf89"
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mq-Xlt-fGV07"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "from datasets import  Dataset, load_metric\n",
    "from evaluate import load\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch import nn\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from transformers import  AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VU5xEO_S_PJm",
    "outputId": "181abdba-bb56-4519-a25b-ad9d5d0439da"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38-_I6gYvBHP"
   },
   "source": [
    "# Работа с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "SCwuAaSLGZ_x",
    "outputId": "c99eb28c-a727-4ccf-c6b8-cde15caeeb2e"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('/content/Совсем окончательный датасет.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "2bfdTRByMpYe",
    "outputId": "67b7f4a0-b9f3-4635-f1df-1d56f6b677d9"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "hXxMYrWAObSF",
    "outputId": "f547da7d-e856-4243-faff-0c161494f26c"
   },
   "outputs": [],
   "source": [
    "class_counts = df['1 level'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "ISQhPQzROuZH",
    "outputId": "5b6818c9-7a89-4dec-96e1-ff43dd392965"
   },
   "outputs": [],
   "source": [
    "df['conn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRvyBL8KQzCf"
   },
   "outputs": [],
   "source": [
    "copy_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "collapsed": true,
    "id": "bXSOeWnGQqs7",
    "outputId": "230ab494-d736-4bd4-9454-e392cd049217"
   },
   "outputs": [],
   "source": [
    "#перекодирую коннотацию из текста в числа\n",
    "names={'conn': {'negative': 0, 'neutral': 1, 'positive': 2}}\n",
    "coded_result = copy_df.replace(names)\n",
    "coded_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tt6-rIGgvT9T"
   },
   "source": [
    "Номера  классов второго уровння начинаются не с 0, поэтому перекодирую их в номера с 0 по 10. Получилось, что классы с первого по третий сохраняют свое обозначение, а остальные меняются в соответствии со словарем ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MO2hKIoTvuXC"
   },
   "source": [
    "Пока сделаю самый простой вариант и попробую обучить на классах второго уровня, поэтому удаляю ненужные колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8e6m02ZP7S1_"
   },
   "outputs": [],
   "source": [
    "mixed_df = coded_result.drop(['Full context', 'conn'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "collapsed": true,
    "id": "LkcpmOvD8F5i",
    "outputId": "b592f035-e8a1-4622-d55f-d204ee756520"
   },
   "outputs": [],
   "source": [
    "mixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-waOzx62cZa"
   },
   "outputs": [],
   "source": [
    "def tokenize(data, tokenizer):\n",
    "    return tokenizer(\n",
    "        data[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=120\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXxTwCf74o73"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    accuracy_metric = load(\"accuracy\")\n",
    "    precision_metric = load(\"precision\")\n",
    "    recall_metric = load(\"recall\")\n",
    "    f1_metric = load(\"f1\")\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    calculated_metric = {}\n",
    "    #отдельно вычисляю accuracy, т.к. для нее average не предусмотрен\n",
    "    calculated_metric.update(accuracy_metric.compute(predictions=predictions,\n",
    "                                                     references=labels))\n",
    "\n",
    "    for metric in [precision_metric, recall_metric, f1_metric]:\n",
    "      calculated_metric.update(metric.compute(predictions=predictions,\n",
    "                                              references=labels,\n",
    "                                              average=\"weighted\"))  #при дисбалансе классов\n",
    "    #метрики для каждого класса\n",
    "    unique_labels = np.unique(labels)\n",
    "    if len(unique_labels) > 2:\n",
    "        for label in unique_labels:\n",
    "             calculated_metric.update({\n",
    "                f\"precision_class_{label}\": precision_score(\n",
    "                    labels, predictions, average=None)[label],\n",
    "                f\"recall_class_{label}\": recall_score(\n",
    "                    labels, predictions, average=None)[label],\n",
    "                f\"f1_class_{label}\": f1_score(\n",
    "                    labels, predictions, average=None)[label]\n",
    "            })\n",
    "    return calculated_metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8brWtDOv4lz"
   },
   "source": [
    "# Предсказание значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_q79Byx8y2zv",
    "outputId": "725c8bef-3d48-41c0-a18a-55480e606eb3"
   },
   "outputs": [],
   "source": [
    "num_labels =  len(set(mixed_df[\"1 level\"]))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ettVU5U2NTfd"
   },
   "outputs": [],
   "source": [
    "model_name = \"DeepPavlov/rubert-base-cased-conversational\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"single_label_classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DR0tiL3mv-iZ"
   },
   "source": [
    "Так как датасет у меня небольшой, в качестве обучающей выборки возьму 0.7 от всего датасета, а на  валидационную и тестовую уйдет по 0.15 датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q45fWKaTNWNI"
   },
   "outputs": [],
   "source": [
    "def split_data():\n",
    "  X_train, X,  y_train, y = train_test_split(mixed_df['marked_text'],\n",
    "                                                  mixed_df['1 level'],   #столбец, значения в котором хотим  предсказать\n",
    "                                                  test_size = 0.3,  #доля тестовой выборки от общего числа данных\n",
    "                                                  random_state = 42,\n",
    "                                                  stratify = mixed_df['1 level'])  #столбец,  по которому стратифицируем данные\n",
    "\n",
    "  X_test, X_val, y_test, y_val = train_test_split(X, y,\n",
    "                                                test_size = 0.5,\n",
    "                                                random_state = 42,\n",
    "                                                stratify=y)\n",
    "  return (\n",
    "        Dataset.from_dict({\"text\": X_train.tolist(), \"labels\": y_train.tolist()}),\n",
    "        Dataset.from_dict({\"text\": X_val.tolist(), \"labels\": y_val.tolist()}),\n",
    "        Dataset.from_dict({\"text\": X_test.tolist(), \"labels\": y_test.tolist()})\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14BvMkAswvQv"
   },
   "source": [
    "Ниже два мейна, которые я запускала с разными гиперпараметрами. Рабочий - первый, результатов второго я не дождалась, так как файнтюнинг, похоже, длился бы 3 часа или больше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "26774ce360ac4d1b8e25cb7da795e2d7",
      "531bdb3d112f424281497c70d14a7803",
      "bd53f443b98142c598a33649e5ff0afe",
      "a2982671f878406c88a2d7e13d86afcb",
      "b54ce1b4c8ee4933af56db45eceb6d6d",
      "3a4d52468ae34cec8b8d4a8f9d37f2ec",
      "7769cfc6bae146d6950928c6ed83921a",
      "3fc034cf863b4a09a24170835da80605",
      "ec11734621e245ae92fae6e50aa7e303",
      "fbcc1fd3b36d4cd2b3e07b6dc132ac94",
      "98b5c2b7339d4cceb66b285baf8d4f05",
      "3a93153bbc5a4d1abcb2274ab39241ad",
      "35cd68c6ded1402689a7aecbbb4f4293",
      "6f413691c3fd4e24a08d9970b6cbbd3b",
      "8a5ab9e3433f49f3b1c9d291ea409886",
      "155ced7b75f446feb1d067bd0b737533",
      "8d5fb481e1954a36a5308c5259d5fe0d",
      "2bcf24f2849e4728ad4da6fa3cb2646a",
      "18ade527b55648b48c8cb9411fd1f2bc",
      "969f69095684444a8821db96b871acce",
      "602c12d59e6a4d6c873748b078f4002d",
      "2a627458630d421ea78c638f1bb74b23",
      "9fcd87b47ec04ebb8fbb16af0a23c9e6",
      "03908fa3784a46f2afa2c374f80565f2",
      "60ce6324c603430cb452db49424ff7dc",
      "b3d74e2f8a644238bfb6dc50b49d7c68",
      "7a5986f2c3fd40d2b94e4be47e6ea6a1",
      "6d97052396884e9aa6dc78c29d31ce27",
      "e684e81ac53541c1bc71659afe2abca5",
      "5b88e615f49a42f58071e9260a688e9b",
      "bf196e4a327942db9e2b7c8b45a37347",
      "b7015613f4d04231abd1b07d9bbcfa3b",
      "cd33aded051a4ce3a2e9a443f2eff2f1",
      "f82bc08095604e9c946c5466ab38281c",
      "c003803b783147e390c1225fe8ffae09",
      "28e51a98e88b4354afdc759a5553a355",
      "973864cd15e0439db842e4a813f07e03",
      "f4ceee1e34d84ee1b8617a568fa35466",
      "0312255fcbf9404cbd1f5cfb3a7712f9",
      "a9b352d9edad4750b2ad7e62bbb5a3ca",
      "5bba3e3c0e494623b5290c150ba350d8",
      "83c94e3d536f401697cc3f7d63b30034",
      "0182ad92c0544cebb0937881874dfb94",
      "7ae8e2889f3c4f2fb674d12fb486ea5d",
      "b165fdcd39b74219987e4e844a02bca6",
      "29a5ecf848ce4d25847b78bbd68573d5",
      "48cca7293a2a4970b79246fc09035b81",
      "229226542df84f26ad03b6071e71296d",
      "e832e00347794f85ab4a4b9e336ebb2e",
      "c8f8e440562d41968a68f0dac19ef2a1",
      "137bbb93e33046cb9363ff2eb8b2044d",
      "363b37bd2b444a78a01b5aa140eed199",
      "481101584b6446b8ad1df39c5b9103a7",
      "45907c99c8eb4b0ab2a6eec43cf9f48a",
      "b1da20031155407494bf56b7d37c647a",
      "1199269a34b646b9973ef9fd727716a5",
      "426989dce0ac42629b01d1eaa36f3599",
      "1de67e3927a2466295adcc440e9858eb",
      "9c2b0fe35d0b4fb9b0c2673960922c1b",
      "a84dcabfd76c4e50b648f5205df29038",
      "99cd19786b254555a01b5b9ce08e0e44",
      "39e6d1fc6624455cbd8a0d80e2adad4e",
      "684d80c758fd4a6e8aec7607d17736c3",
      "371ee08149664c95bbc4669ca7a346cc",
      "479e0ed639664511846e2f08a663b0a5",
      "eb076313811e471f8523e6f2122b9bdc",
      "9b83247752cc43299e0f363dd07c87fa",
      "9a25bc738aa94e61bb750fa61a0f5fc7",
      "403901caafd04d3d89e7a1dae188ea1f",
      "f41807dcc5864280827d5beda876c57e",
      "058fef5bb6b6460db6d9d87d9597abe7",
      "bf7fd05bf1e245d38855c43d1315fe2a",
      "08b5886fbf4646c3bf9f6c6cb3bce58c",
      "030a9d6037d44754b2a65695ccb860f6",
      "fbdf7cde69ee42ae818cc0b3204402af",
      "266201071b194cafa402a4984a42fa1b",
      "9dd5698182a84f2ba80a75080e80465d"
     ]
    },
    "collapsed": true,
    "id": "zG5qvGFvTTz9",
    "outputId": "2ecc8571-6879-49ae-ae9e-df74dabb5083"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  X_train, X_val, X_test = split_data()\n",
    "  tokenized_train = X_train.map(\n",
    "        lambda x: tokenize(x, tokenizer),\n",
    "        batched=True)\n",
    "\n",
    "  tokenized_val = X_val.map(\n",
    "        lambda x: tokenize(x, tokenizer),\n",
    "        batched=True)\n",
    "\n",
    "\n",
    "  tokenized_test = X_test.map(\n",
    "        lambda x: tokenize(x, tokenizer),\n",
    "        batched=True)\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=50)\n",
    "\n",
    "  trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics,)\n",
    "\n",
    "  print(\"происходит файнтюнинг\")\n",
    "  trainer.train()\n",
    "\n",
    "  print(\"результаты на валидационной выборке\")\n",
    "  val_results = trainer.evaluate()\n",
    "  for key, value in val_results.items():\n",
    "      if key.startswith('eval_'):\n",
    "          print(f\"{key[5:]}: {value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "  model.save_pretrained(\"./fine_tuned_model\")\n",
    "  tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
    "  print(\"Модель сохранена в fine_tuned_model/\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuf4Zb5XxixI"
   },
   "source": [
    "Судя по метрикам, нулевой класс (бывший класс №8) не предсказывается совсем. Это предсказуемо, учитывая, что его экземпляров  не очень много, всего 60. Класс 6 и 8 тоже предсказывается не очень хорошо, но их экземпляров тоже не очень много, около 70-80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyQhW17MZl5h"
   },
   "outputs": [],
   "source": [
    "#сохраняю в гугл драйв папку с моделью\n",
    "!cp -r /content/fine_tuned_model /content/drive/MyDrive/2level_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWNyRkdjAIVD"
   },
   "outputs": [],
   "source": [
    "finetuned_model_path = \"/content/drive/MyDrive/2level_model\"\n",
    "finetuned_tokenizer_path = \"/content/drive/MyDrive/2level_model\"\n",
    "ft_model = AutoModelForSequenceClassification.from_pretrained(finetuned_model_path)\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained(finetuned_tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-8JIzN-_JC9"
   },
   "outputs": [],
   "source": [
    "#создание confusion matrix\n",
    "def plot_confusion_matrix_11_classes(test_dataset):\n",
    "    trainer = Trainer(model=ft_model)\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    preds = np.argmax(predictions.predictions, axis=1)\n",
    "    labels = test_dataset[\"labels\"]\n",
    "\n",
    "    #создаем подписи для классов\n",
    "    class_names = [f\"Class {i}\" for i in range(11)]\n",
    "\n",
    "    #Confusion Matrix\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "\n",
    "    #перевожу в проценты\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    #настройка размера графика для 11 классов\n",
    "    plt.figure(figsize=(15, 12))\n",
    "\n",
    "    #визуализация\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.title(\"Normalized Confusion Matrix (11 классов)\", pad=20, fontsize=16)\n",
    "    plt.xlabel(\"Predicted\", fontsize=14)\n",
    "    plt.ylabel(\"True\", fontsize=14)\n",
    "\n",
    "    #сохранение\n",
    "    plt.savefig(\"/content/drive/MyDrive/2level_model/confusion_matrix_11_classes.png\",\n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    #Classification Report\n",
    "    print(classification_report(labels, preds, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "16b8833ab6404d7e9b143417b21294e7",
      "79994498120c44f0a7a9f17e11958f14",
      "5dbfcf503991421db4f13f4f140750cc",
      "aa2fc96f93a9447fbeb8a4cb03570406",
      "be64d8ce21524a51924bd5bd3cbc85b0",
      "e044d60d926c4d59887e129fef4d30fb",
      "18f9b7c1d91941ae9921ad7a2143c398",
      "db46d0d2ae8a4d69baf2046723eacef0",
      "d8bc79a85e9240f58d54e110a90da523",
      "28e048c1934547fb8def2b397cc6b8b1",
      "d6c8d9e3264e4e109d619c416077bbca"
     ]
    },
    "id": "q2lanwiehMrN",
    "outputId": "b45ba7db-99c1-4fc7-ec9f-58b7b6ff27f8"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = split_data()\n",
    "\n",
    "tokenized_test = X_test.map(\n",
    "        lambda x: tokenize(x, tokenizer),\n",
    "        batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QxtomdFhAE_D",
    "outputId": "b54b0934-6860-4bb3-c29a-6bcf722ce733"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix_11_classes(tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ0H_yAMuVT_"
   },
   "source": [
    "## Проверяю работу модели на отдельных  примерах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8xJ7W-6k9lz"
   },
   "outputs": [],
   "source": [
    "def predict_meaning (context: str, lexeme: str, model, tokenizer):\n",
    "  marked_context = context\n",
    "  inputs = tokenizer(\n",
    "        marked_context,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "  with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "  probs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()[0]\n",
    "  predicted_class = np.argmax(probs)\n",
    "\n",
    "  result = {\"lexeme\": lexeme,\n",
    "            \"context\": marked_context,\n",
    "            \"predicted_class\": int(predicted_class),\n",
    "            \"confidence\": float(probs[predicted_class]),\n",
    "            \"all_probs\": probs.tolist()\n",
    "        }\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-QJrPAravVMh",
    "outputId": "6878268e-faf6-44b0-bc61-a97cae9ff3ca"
   },
   "outputs": [],
   "source": [
    "res1 = predict_meaning(\"мы с моей [TGT]чувихой[/TGT] вчера были на концерте\", \"чувиха\", ft_model, ft_tokenizer)\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHbcLlyjoGzn",
    "outputId": "7a35e756-2324-4ab0-8351-12809a825ace"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"я всегду буду твоим [TGT]бро[/TGT], даже если мы поссоримся\", \"бро\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwiR5smDw2P-",
    "outputId": "e411bd48-9b50-48eb-b07c-2b875e29a905"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"я уже все понял по каждому [TGT]бро[/TGT] и можешь не пытаться меня переубедить\", \"бро\", ft_model, ft_tokenizer)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTZ90eXvrI3w",
    "outputId": "afe00797-929f-4d0c-a161-e41f3f163348"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"будь [TGT]бро[/TGT], помоги нам выиграть в этом конкурсе\", \"бро\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zy5twKoBrdl2",
    "outputId": "b9f683c7-9b64-418e-bee1-c412f35f6953"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"спасибо [TGT]бро[/TGT] за помощь в организации вечеринки\", \"бро\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gv2317NwxGoX",
    "outputId": "3fb16a3d-f4ce-45d0-b9ad-ed92354752fc"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"ты мой [TGT]бро[/TGT] навсегда, только скажи мне, поедешь ли ты с нами в москву\", \"бро\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JG-90lYIvRzc",
    "outputId": "512967e6-4c77-40ea-ba30-7ac5d7281d1a"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"Затем он говорил [TGT]мальчикам[/TGT]: «Именно так работает поэзия.\", \"мальчик\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k28NmrybzKz0",
    "outputId": "6a9434d3-962a-4cb7-e3b0-f51862d590d0"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"Какой ты гениальный [TGT]мальчик[/TGT]! Я бы ведь сама не догадалась так сделать\", \"мальчик\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxUtg20L0Iae",
    "outputId": "e866a621-a43a-4361-bb79-b4eb06ccfba6"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"Хочу оставаться [TGT]женщиной[/TGT], а не превращаться в  сапожника\", \"женщина\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3sbZjqE4FF9",
    "outputId": "fd6356c9-0122-4150-e00b-5b2dfc7bd09d"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"мы с [TGT]пацанами[/TGT] часто собираемся вместе.\", \"пацан\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6nZjXLRUlYN6",
    "outputId": "5fd5c893-6c07-4bf2-f482-476d24b226a8"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"мы с моими [TGT]девами[/TGT] пошли вчера вместе за кофе.\", \"дева\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plaUOXZEtR7T",
    "outputId": "b3bce8dc-6e72-4772-c22c-9ca2a426484a"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"у [TGT]деда[/TGT] дома или у меня решили собраться.\", \"дед\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Seg2tOQhtkyD",
    "outputId": "25173a18-6a1b-427d-acec-163b50f37647"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"[TGT]дед[/TGT] мне представлялся человеком очень спокойным\", \"дед\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "roMkA6UsyOhI",
    "outputId": "6af665e0-c31a-4a0d-8c50-02788e73a2a4"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"зачем вы так строго с ним, жалко [TGT]деда[/TGT]\", \"дед\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WklNDkCuts1r",
    "outputId": "833d813a-be30-4460-d778-cbf0dc36a769"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"тебе [TGT]деды[/TGT] местные ничего не сказали?\", \"дед\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W4-Z9RYFLlQg",
    "outputId": "082a64f4-b9f6-4797-a1d7-ef8ed245943b"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"[TGT]мужчина[/TGT] услышал крики и решил помочь несчастным\", \"мужчина\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zd5zZigqOPpY",
    "outputId": "b3650214-0def-4874-b2ed-1dff786b2b65"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"ради такой [TGT]женщины[/TGT] я был бы готов на многое\", \"женщина\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EN6eT6KNNWXO",
    "outputId": "6889fc24-6ff0-49aa-e8c8-c1587f7c990a"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"[TGT]женщина[/TGT] показалась нам очень понимающей\", \"женщина\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GgktBhvhLbJZ",
    "outputId": "6b5dbf81-5f3b-4149-c144-90432f5ac968"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"вокруг так много красивых [TGT]женщин[/TGT].\", \"женщина\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qYVmuVPP1YY",
    "outputId": "22264c77-ef2d-46ba-e6f0-7ac1886f50d0"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"[TGT]женщина[/TGT] сказала, что пойдет с нами.\", \"женщина\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeiymTb8vI_F",
    "outputId": "0e60bbc2-6873-4b03-acfc-1c03c3702104"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"меня очень тронули слова этого [TGT]деда[/TGT]\", \"дед\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfFxgVU7TdkG",
    "outputId": "0d08ebeb-4f97-42e5-b1f8-9197cbcd21ef"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"зачем [TGT]герл[/TGT] обижаешь\", \"герл\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7QjH2LSyW38A",
    "outputId": "1819f677-73b0-4b7b-bfd1-5f4493ae87fd"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"[TGT]пацаны[/TGT] это вам во дворе сказали?\", \"пацан\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPFp2l2yXjRD",
    "outputId": "6f0d0ce2-ad5e-4913-dc5a-1eea74b6e208"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"такая хот [TGT]герл[/TGT] мне навстречу вышла\", \"герл\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_TIIWY7t1Ru",
    "outputId": "2e6a4987-b44a-40b7-f7da-9e9ce3eebfd2"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"бар [TGT]герл[/TGT] сегодня не та, что обычно\", \"герл\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Obd6VBsNsXGJ",
    "outputId": "e760bc95-664b-4f83-9fe1-9fb6aa7f2f66"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"надоела эта клин [TGT]герл[/TGT]\", \"герл\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XblDEzCs-V_",
    "outputId": "6c746306-bb73-4453-99f0-46bafcb946e1"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"он такой эстетик [TGT]мэн[/TGT]\", \"мэн\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcNEa9D46E_M",
    "outputId": "e8bf0463-046c-4db7-98fb-dd76cdd1ac14"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"ему сказал какой-то [TGT]челик[/TGT] давай вместе съездим\", \"чел\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGv8at6I6OTT",
    "outputId": "fc89c949-b49d-46db-e75c-9fc2441eeffe"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"тебе же [TGT]чел[/TGT] из германии кроссы привез\", \"чел\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHRnS-ZP6md0",
    "outputId": "1d14b99e-e673-495d-d6cb-263e17985572"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"[TGT]чел[/TGT], покупающий плойку в первый раз может и не разберется, \", \"чел\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arl5G05T8cdu",
    "outputId": "29a1de3e-06b9-4ed4-9bdf-40c389b9031f"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"[TGT]чел[/TGT] с какой то сумкой это странно\", \"чел\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLeNqO2f9cNy",
    "outputId": "0fa0bc37-cb90-4bec-f557-bd04a4c3a605"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"[TGT]чел[/TGT] не до конца понял этот фильм\", \"челик\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqbya1-r9uWS",
    "outputId": "ecf62676-939f-4061-dcf6-5f84dba7505d"
   },
   "outputs": [],
   "source": [
    "res = predict_meaning(\"[TGT]челик[/TGT] просто все еще бомбит что не получилось\", \"челик\", ft_model, ft_tokenizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tnyc0D-8rIVl"
   },
   "source": [
    "# Предсказание коннотации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dn19_lUzrL-F"
   },
   "outputs": [],
   "source": [
    "conn_df = coded_result.drop(['Full context', '1 level'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "np5OWeMudwg_",
    "outputId": "b3f73646-a3fe-4dc4-f771-e21e68f59c90"
   },
   "outputs": [],
   "source": [
    "conn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjSj1zeZreSK",
    "outputId": "aab2df15-f02d-445e-9478-62476e2fb2cd"
   },
   "outputs": [],
   "source": [
    "num_labels_conn =  len(set(conn_df[\"conn\"]))\n",
    "num_labels_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2LRor44rpSK"
   },
   "outputs": [],
   "source": [
    "def split_data_conn():\n",
    "  X_train, X, y_train, y = train_test_split(conn_df['marked_text'],\n",
    "                                                  conn_df['conn'],   #столбец, значения в котором хотим  предсказать\n",
    "                                                  test_size = 0.3,  #доля тестовой выборки от общего числа данных\n",
    "                                                  random_state = 42,\n",
    "                                                  stratify = conn_df['conn'])  #столбец,  по которому стратифицируем данные\n",
    "\n",
    "  X_test, X_val, y_test, y_val = train_test_split(X, y,\n",
    "                                                test_size = 0.5,\n",
    "                                                random_state = 42,\n",
    "                                                stratify=y)\n",
    "  return (\n",
    "        Dataset.from_dict({\"text\": X_train.tolist(), \"labels\": y_train.tolist()}),\n",
    "        Dataset.from_dict({\"text\": X_val.tolist(), \"labels\": y_val.tolist()}),\n",
    "        Dataset.from_dict({\"text\": X_test.tolist(), \"labels\": y_test.tolist()})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4-ZI-8uVFUM"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayYKcTUZWJdl"
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, sampler=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "\n",
    "        if self.sampler is not None:\n",
    "            return torch.utils.data.DataLoader(\n",
    "                self.train_dataset,\n",
    "                batch_size=self.args.train_batch_size,\n",
    "                sampler=self.sampler,\n",
    "                collate_fn=self.data_collator,\n",
    "                drop_last=self.args.dataloader_drop_last,\n",
    "                num_workers=self.args.dataloader_num_workers,\n",
    "                pin_memory=self.args.dataloader_pin_memory,\n",
    "            )\n",
    "        else:\n",
    "            return super().get_train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724,
     "referenced_widgets": [
      "d3660656237e428db85c5f4e6709350b",
      "51a3de01dbbf4bb4b0a981ae6b8b339d",
      "a1a0946100e04263a7a433284240bf6e",
      "99a55624124745c7b4b2b19f150711ef",
      "5c6eccf1a9594b9eb671bc6caf540e3d",
      "6ee0014af138401d840d0b3e71947893",
      "852a1a29901b4a159d57567d681655db",
      "b077485b507e4d45b54651db8f0eda6e",
      "da112f8a0e834cb1877032ba8b9b38b5",
      "5178a9cd24624e27a4c77fe4cec35c35",
      "8eb581cc53644ef5becb53b4395d81e2",
      "9eebfe349e7246b6ad79d4d3bf55eb7b",
      "7bcf37e25f1144adb3973fdd15ce80de",
      "0621173240914084a62e2be1d55c3404",
      "3d0b68f2f5e74c67b93ab990dbe6f5ee",
      "ade79882aa42414cb8ee9e13a8df9301",
      "f870043a998a42c596276515ea2a6fad",
      "272cd2c6c3b944fa8c012903d784a47c",
      "62154bc6390a456396904b1b1efe7c1d",
      "791034008dea41c09c18aa90c428745f",
      "ed709381dee048b0a10b0d7e28765e29",
      "aea8faede26e45e88239f2694e771f3d",
      "2be6d3d7fe5f4e0eabcfadaeb820fd73",
      "520b7ebe11fc4daea13a3bcf96646142",
      "d4ec6eb9e7bb4d6db941e02205466585",
      "0a3e53050c70446ca6d152338b6d95fc",
      "a805c94ca77d4d61ad0d1699717f2944",
      "3b53d9313652402688b58c5c08cd6a7a",
      "67458d9c8aa9492a95f7cc46254778e4",
      "887ca59c3cf64ab396e8a04b4ae55588",
      "65eff5ebe47340e392a2e126e621f8cd",
      "74a99b9346d6470485599ece6a8bd34c",
      "39db76f27cc84ec681785c076abc4868"
     ]
    },
    "collapsed": true,
    "id": "wsxJfKTtHZ2K",
    "outputId": "069a52e8-be66-494c-ac64-92ee797b987c"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  X_train, X_val, X_test = split_data_conn()\n",
    "  labels = np.array(X_train[\"labels\"])\n",
    "\n",
    "  class_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(labels),\n",
    "        y=labels)\n",
    "\n",
    "  class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "  model_name = \"DeepPavlov/rubert-base-cased-conversational\"\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "  model_conn = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                  num_labels=3,\n",
    "    problem_type=\"single_label_classification\")\n",
    "\n",
    "  model_conn.classifier = nn.Linear(model_conn.config.hidden_size, 3)\n",
    "  model_conn.loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "  sampler = WeightedRandomSampler(weights=class_weights[labels],\n",
    "                                  num_samples=len(labels),\n",
    "                                  replacement=True)\n",
    "\n",
    "\n",
    "  tokenized_train = X_train.map(\n",
    "        lambda x: tokenize(x, tokenizer),\n",
    "        batched=True)\n",
    "\n",
    "\n",
    "  tokenized_val = X_val.map(\n",
    "        lambda x: tokenize(x, tokenizer),\n",
    "        batched=True)\n",
    "\n",
    "\n",
    "  tokenized_test = X_test.map(\n",
    "        lambda x: tokenize(x, tokenizer),\n",
    "        batched=True)\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "    output_dir=\"./balanced_results\",\n",
    "    per_device_train_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=50)\n",
    "\n",
    "  trainer = CustomTrainer(\n",
    "        model=model_conn,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics,\n",
    "        sampler=sampler)\n",
    "\n",
    "  print(\"происходит файнтюнинг\")\n",
    "  trainer.train()\n",
    "\n",
    "  print(\"результаты на валидационной выборке\")\n",
    "  val_results = trainer.evaluate()\n",
    "  for key, value in val_results.items():\n",
    "      if key.startswith('eval_'):\n",
    "          print(f\"{key[5:]}: {value:.4f}\")\n",
    "\n",
    "\n",
    "  model_conn.save_pretrained(\"./fine_tuned_conn_model_sampling\")\n",
    "  tokenizer.save_pretrained(\"./fine_tuned_conn_model_sampling\")\n",
    "  print(\"Модель сохранена в fine_tuned_conn_model_sampling/\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXrlLW2kWsON"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/fine_tuned_conn_model_sampling /content/drive/MyDrive/conn_sampling__model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qypmmKsY0qd",
    "outputId": "853f29ab-28e4-4f74-a9eb-8cefd0a78546"
   },
   "outputs": [],
   "source": [
    "ft_conn_model_path = \"/content/drive/MyDrive/conn_sampling__model\"\n",
    "ft_conn_tokenizer_path = \"/content/drive/MyDrive/conn_sampling__model\"\n",
    "ft_conn_model = AutoModelForSequenceClassification.from_pretrained(ft_conn_model_path)\n",
    "ft_conn_tokenizer = AutoTokenizer.from_pretrained(ft_conn_tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZnjSzfpD0xe"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_dataset):\n",
    "    trainer = Trainer(model=ft_conn_model)\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    preds = np.argmax(predictions.predictions, axis=1)\n",
    "    labels = test_dataset[\"labels\"]\n",
    "\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\"],\n",
    "                yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\"])\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(\"/content/drive/MyDrive/conn_sampling__model/confusion_matrix.png\")\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(labels, preds, target_names=[\"Class 0\", \"Class 1\", \"Class 2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "051ae3da40e241c898527fe892912d11",
      "0f06e4e634334f088e089644e6e703a2",
      "bae9370d303d4c8c91bc39cc8e577e55",
      "ccc7fed1ee354fd9b3fe3b96fe0d5448",
      "4151d1cba39449e2ae142c70b27972a0",
      "90030558f4844fb5850114cda0e976bb",
      "2225adee54444e05901e0a0103cc523c",
      "621b7c19ee004cd483612bf39d969cbc",
      "6136f1093dfd4e829c644a3e8d560002",
      "07a26e776b4f49799f25ade88b05ff05",
      "5663203d965c4ad5b1a1530599443159"
     ]
    },
    "id": "vsDOfoWqXgDL",
    "outputId": "2657b3ef-e5b0-4f73-e27a-e1c345f4005f"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = split_data_conn()\n",
    "\n",
    "tokenized_test = X_test.map(\n",
    "        lambda x: tokenize(x, ft_conn_tokenizer),\n",
    "        batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HeiSuSoCENRZ",
    "outputId": "d6c7732a-e54b-488f-86ae-323acceda16c"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gkiae1H7yMZq"
   },
   "source": [
    "## Проверяю работу модели на отдельных примерах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "kSECCQEr0SC5",
    "outputId": "cac4ed69-2e9b-419c-e001-0faeca082a1d"
   },
   "outputs": [],
   "source": [
    "conn = predict_meaning(\"Какой ты гениальный мальчик, я бы ведь мама не догадалась так сделать!\", \"мальчик\", ft_conn_model, ft_conn_tokenizer)\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fk1oxZKA1tb8",
    "outputId": "9a9bdcbf-0581-4602-8f36-ecab7b28ecad"
   },
   "outputs": [],
   "source": [
    "conn = predict_meaning(\"ну что ты как девочка? Реши хоть что-то сам и не ной!\", \"девочка\", ft_conn_model, ft_conn_tokenizer)\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1pHXqUFVtCQ",
    "outputId": "c6688fd0-5aac-462d-cb3b-c1d66f815f8a"
   },
   "outputs": [],
   "source": [
    "conn = predict_meaning(\"моя герл - огонь, с ней не соскучишься!\", \"герл\", ft_conn_model, ft_conn_tokenizer)\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0g9W3xynX1st",
    "outputId": "d619012a-b35b-48fa-9fa6-839512d9c330"
   },
   "outputs": [],
   "source": [
    "conn = predict_meaning(\"Чел реально заморочился\", \"чел\", ft_conn_model, ft_conn_tokenizer)\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RY1jmhyKJbl"
   },
   "source": [
    "# Бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZF-ndZ52tftD"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_test = split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iB0on1uDKNdt",
    "outputId": "3a66c844-532e-4e87-f33e-67ddaa0e2d75"
   },
   "outputs": [],
   "source": [
    "class_counts = np.bincount(y_train)\n",
    "class_probabilities = class_counts / len(y_train)\n",
    "y_pred_baseline = np.random.choice(len(class_probabilities), size=len(y_test), p=class_probabilities)\n",
    "baseline_precision = precision_score(y_test, y_pred_baseline, average=\"weighted\")\n",
    "baseline_f1 = f1_score(y_test, y_pred_baseline, average=\"weighted\")\n",
    "baseline_recall = recall_score(y_test, y_pred_baseline, average=\"weighted\")\n",
    "\n",
    "print(f\"Precision бейзлайна: {baseline_precision}: Recall {baseline_recall}; f1: {baseline_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unX_43h0wm9P"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_test = split_data_conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaXmtuHzwsWY",
    "outputId": "035d9f3b-255f-4572-f14e-f9813212f38e"
   },
   "outputs": [],
   "source": [
    "class_counts = np.bincount(y_train)\n",
    "class_probabilities = class_counts / len(y_train)\n",
    "y_pred_baseline = np.random.choice(len(class_probabilities), size=len(y_test), p=class_probabilities)\n",
    "baseline_precision = precision_score(y_test, y_pred_baseline, average=\"weighted\")\n",
    "baseline_f1 = f1_score(y_test, y_pred_baseline, average=\"weighted\")\n",
    "baseline_recall = recall_score(y_test, y_pred_baseline, average=\"weighted\")\n",
    "\n",
    "print(f\"Precision бейзлайна: {baseline_precision}: Recall {baseline_recall}; f1: {baseline_f1}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
